{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as py\n",
    "def plot_gauss(mu,sigma, lim):\n",
    "    ''' Funkcja rysująca kontury funkcji gęstości prawdopodobieństwa \n",
    "       dwuwymiarowego rozkładu Gaussa'''\n",
    " \n",
    "    x = np.arange(lim[0], lim[1], 0.1)\n",
    "    y = np.arange(lim[2], lim[3], 0.1)\n",
    "    X,Y = np.meshgrid(x, y)\n",
    "    X.shape = 1,len(x)*len(y)\n",
    "    Y.shape = 1,len(x)*len(y)\n",
    "    P = np.vstack((X,Y))\n",
    "    invS = np.linalg.inv(sigma)\n",
    "    R = P.T-mu\n",
    "    z = np.zeros(len(R))\n",
    "    for i in range(len(R)):\n",
    "        z[i] = np.exp(-0.5*np.dot( R[i,:].T,np.dot(invS,R[i,:])))\n",
    " \n",
    "    z.shape = len(x),len(y)\n",
    "    py.contourf(x,y,z,alpha = 0.5)\n",
    "    py.plot(mu[0],mu[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Powtórka\n",
    "* Możliwe wyniki zastosowania klasyfikatora binarnego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1ojQ4IABTw7CspkVhqIKD6t3Pz7gjK1Kv\" width = 800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Konstrukcja krzywej ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1pXcIw5fdG2BN3gOYcuB0Gm1WpX8nqBrO\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* kross-walidacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* generalizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorytmy generatywne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wstęp\n",
    "\n",
    "Dotychczas mówiliśmy tylko o algorytmach uczących bazujących na modelowaniu rozkładów warunkowych zmiennych zależnych $y$ przy zadanym $x$ i sparametryzowanych przez $\\theta $: \n",
    "\n",
    "$\\qquad p(y|x;\\theta )$, \n",
    "\n",
    "np.: regresja liniowa, logistyczna czy softmax.\n",
    "\n",
    "Na podstawie przykładów z ciągu uczącego estymowana jest pewna granica między dwoma obszarami przestrzeni wejść. Decyzja co do klasy, którą reprezentuje nowy przypadek zależy tylko od tego, po której stronie granicy znajduje się ten przypadek.\n",
    "\n",
    "Algorytmy, które estymują wprost rozkłady $(y|x)$ czy też mapowania z $X \\rightarrow \\lbrace 0,1\\rbrace $ nazywamy **algorytmami dyskryminacyjnymi**.\n",
    "\n",
    "Poniżej przykład 1D i 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# tworzymy jednowymiarowy zbiór uczący\n",
    "\n",
    "xmin, xmax = -5, 5\n",
    "n_samples = 100 \n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n_samples)\n",
    "y = (X > 0).astype(np.float) # przypisujemy klasę\n",
    "X[X > 0] *= 4 \n",
    "X += .3 * np.random.normal(size=n_samples) # torchę mieszamy punkty aby podział na klasy nie byl tak oczywisty\n",
    "X = X[:, np.newaxis]\n",
    "\n",
    "# tworzymy i uczymy klasyfikator\n",
    "clf = linear_model.LogisticRegression(C=1e5, solver='lbfgs')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# rysujemy wyniki\n",
    "plt.figure(1, figsize=(14, 5))\n",
    "plt.clf()\n",
    "plt.scatter(X.ravel(), y, color='black', zorder=20)\n",
    "X_test = np.linspace(-5, 10, 300)\n",
    "\n",
    "\n",
    "def hipoteza(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "h = hipoteza(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(X_test, h, color='red', linewidth=3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('klasa')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# ilustracja:\n",
    "np.random.seed(0)\n",
    "X = np.random.randint(20,size=(20,2))\n",
    "theta = np.array([[-0.2],[0.3]])\n",
    "Y = np.round( 1/(1+np.exp(np.dot(-X, theta))))\n",
    "ind0 = np.where(Y==0)\n",
    "ind1 = np.where(Y==1)\n",
    "py.plot(X[ind0,0],X[ind0,1],'bo') \n",
    "py.plot(X[ind1,0],X[ind1,1],'ro')\n",
    "py.xlabel(\"x_0\")\n",
    "py.ylabel(\"x_1\")\n",
    "# szykuję siątkę \n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs') # inicjalizuję model\n",
    "logreg.fit(X, Y.ravel()) # fituję model\n",
    "Z = logreg.predict_proba(np.c_[xx.ravel(), yy.ravel()]) # robię predykcję dla każdego punktu siatki\n",
    "\n",
    "#Z = Z.reshape(xx.shape)\n",
    "py.contourf(xx,yy,Z[:,1].reshape(xx.shape)) # rysuję kontur rozdzielający klasy\n",
    "py.xlim(xx.min(), xx.max())\n",
    "py.ylim(yy.min(), yy.max())\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "W tych dwóch powyższych przykładach przyjrzyjmy się jak powstaje hiperpowierzchnia rozdzielająca klasy.\n",
    "* Jak ma się ona do hipotezy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generatywne algorytmy uczące\n",
    "\n",
    "Algorytmy generatywne modelują:\n",
    "* rozkłady cech w klasach: $p(x|y)$ oraz\n",
    "* prawdopodobieństwa występowania klas: $p(y)$.\n",
    "\n",
    "Na podstawie ciągu uczącego stworzymy osobne modele tego, jakim rozkładom podlegają cechy w poszczególnych klasach. \n",
    "\n",
    "Po otrzymaniu nowego przypadku patrzymy, do której klasy jest on najbardziej podobny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Ilustracja rozkładu cech w poszczególnych klasach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#parametry rozkładu\n",
    "mu1 = [-2,-3] # wektor średnich:\n",
    "Sigma1 = np.array([[1, -0.6], [-0.6, 1]]) # macierz kowariancji:\n",
    "N1 = 300\n",
    "\n",
    "mu2 = [2,3] # wektor średnich:\n",
    "Sigma2 = np.array([[1, 0.6], [0.6, 1]]) # macierz kowariancji:\n",
    "N2 = 150\n",
    "# generujemy dane: \n",
    "z1 = np.random.multivariate_normal(mu1, Sigma1, N1) #\n",
    "z2 = np.random.multivariate_normal(mu2, Sigma2, N2) #\n",
    "py.subplot(1,2,1)\n",
    "py.plot(z1[:,0],z1[:,1],'g.')\n",
    "#py.axis('equal')\n",
    "py.xlabel(\"cecha 1\")\n",
    "py.ylabel(\"cecha 2\")\n",
    "plot_gauss(mu1,Sigma1, [-6,6,-6,6])\n",
    "py.title(\"klasa 0, p(x|y=0)\")\n",
    "\n",
    "py.subplot(1,2,2)\n",
    "py.plot(z2[:,0],z2[:,1],'r.')\n",
    "#py.axis('equal')\n",
    "py.xlabel(\"cecha 1\")\n",
    "py.ylabel(\"cecha 2\")\n",
    "plot_gauss(mu2,Sigma2, [-6,6,-6,6])\n",
    "py.title(\"klasa 1, p(x|y=1)\") \n",
    "py.show()\n",
    "\n",
    "print(\"P(y=0) = N1/(N1+N2): {0:.2f}\".format( N1/(N1+N2)))\n",
    "print('P(y=1) = N2/(N1+N2): {0:.2f}'.format( N2/(N1+N2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rozważmy przykład.\n",
    "Chcemy odróżniać psy ($y=0$) od kotów ($y=1$) na podstawie zdjęć. \n",
    "* Umiemy określać cechy $x$ tych zwierząt. \n",
    "* Budujemy rozkłady tych cech dla psów: $p(x|y=0)$ i dla kotów $p(x|y=1)$. \n",
    "* Modelujemy także prawdopodobieństwo tego, że losowo wybrane zdjęcie przedstawia psa lub kota (np. na podstawie liczebności zdjęć obu gatunków w naszej bazie danych): $p(y)$ (jest to tzw. *prawdopodobieństwo apriori*).\n",
    "* Wtedy można na podstawie wzoru Bayesa obliczyć prawdopodobieństwo a posteriori:\n",
    "\n",
    "$\\qquad$ $p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Klasyfikator Bayesa (związany z prawodpodobieństwem warunkowym)\n",
    "* Wzór Bayesa:  $p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$\n",
    "* $p(x)$ można wyrazić za pomocą prawdopodobieństwa $p(x|y)$ i $p(y)$ następująco: \n",
    "\n",
    "$\\qquad$ $p(x) = p(x|y=0)p(y=0) + p(x|y=1)p(y=1)$.\n",
    "\n",
    "* Warto jednak zauważyć, że w problemie klasyfikacji nie interesuje nas tak naprawdę $p(x)$. Dla obu klas $p(x)$ jest takie same,\n",
    "co ma nas obchodzić szansa na daną ceche jeśli interesuje nas tylko i wyłącznie prawodopodobieństwo, że to dana klasa\n",
    " > Dlaczego? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* W klasyfikacji chcemy odpowiedzieć na pytanie, która z klas jest najbardziej prawdopodobna, czyli dla jakiego $y$ $p(y|x)$ jest maksymalne. \n",
    " * Ponieważ $p(x)$ nie zależy od $y$ więc: \n",
    "\n",
    "$\\qquad$ $ \\arg \\max _y p(y|x) = \\arg \\max _y \\frac{p(x|y)p(y)}{p(x)} = \\arg \\max _y p(x|y) p(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dwuwymiarowe rozkłady Gaussa\n",
    "* Funkcja gęstości prawdopodobieństwa dla $n$-wymiarowego rozkładu o wektorze średnim $\\mu \\in \\mathcal {R}^n$ i macierzy kowariancji $\\Sigma $ dana jest przez:\n",
    "\n",
    "$\\qquad$ $ p(x;\\mu ,\\Sigma ) = \\frac{1}{(2\\pi )^{n/2} |\\Sigma |^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu )^T \\Sigma ^{-1}(x-\\mu )\\right)$\n",
    "\n",
    "gdzie: $|\\Sigma |$ oznacza wyznacznik macierzy $\\Sigma $.\n",
    "* Oczywiście $\\mu $ równe jest wartości oczekiwanej zmiennych z tego rozkładu:\n",
    "\n",
    "$\\qquad$ $E[X] = \\int _x x p(x;\\mu ,\\Sigma )dx = \\mu $\n",
    "\n",
    "Macierz kowariancji natomiast dana jest wzorem:\n",
    "\n",
    "$\\qquad$ $\\Sigma = E[(X-E[X])^T(X-E[X])]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parametry rozkładu\n",
    "mu = [-2,-3] # wektor średnich:\n",
    "\n",
    "for s in np.arange(-0.9,1,0.3):\n",
    "    Sigma = np.array([[1, s],\n",
    "                      [s, 1]]) # macierz kowariancji:\n",
    "    # generujemy dane: \n",
    "    z1 = np.random.multivariate_normal(mu, Sigma, 300) #\n",
    "    py.figure()\n",
    "    py.plot(z1[:,0],z1[:,1],'g.')\n",
    "    py.axis('equal')\n",
    "    py.xlabel(\"cecha 1\")\n",
    "    py.ylabel(\"cecha 2\")\n",
    "    # w tle dorysujemy konturami funkcję gęstości prawdopodobieństwa\n",
    "    plot_gauss(mu,Sigma, [-6,2,-6,2])\n",
    "    py.title(Sigma)\n",
    "    py.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussowska analiza dyskryminacyjna\n",
    "\n",
    "Pierwszym algorytmem generatywnym, z którym się zapoznamy będzie gaussowska analiza dyskryminacyjna (GAD).\n",
    "* W tej analizie zakładamy, że dane niezależne, przy ustalonej klasie, pochodzą z wielowymiarowego rozkładu normalnego: $p(x|y) \\sim N(\\mu , \\Sigma )$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Parametry modelu GAD \n",
    "Dla pełnej specyfikacji modelu gaussowskiej analizy dyskryminacyjnej musimy założyć, że następujące zmienne mają wskazane rozkłady:\n",
    "\n",
    "$\\qquad$\n",
    "$\\begin{matrix}\n",
    "y &\\sim & \\textrm {Bernoulli}(\\phi ) \\\\\n",
    "(x|y=0) &\\sim & N(\\mu _0,\\Sigma_0 ) \\\\\n",
    "(x|y=1) &\\sim & N(\\mu _1,\\Sigma_1 )\n",
    "\\end{matrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "zapisując to przy pomocy odpowiednich funkcji gęstości prawdopodobieństwa mamy:\n",
    "\n",
    "$\\qquad$\n",
    "$\\begin{matrix}\n",
    "p(y) &=& \\phi ^y (1-\\phi )^{1-y}  \\\\\n",
    "p(x|y=0) &=& \\frac{1}{(2\\pi )^{n/2} |\\Sigma_0 |^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu _0)^T \\Sigma_0 ^{-1}(x-\\mu _0)\\right)\\\\\n",
    "p(x|y=1) &=& \\frac{1}{(2\\pi )^{n/2} |\\Sigma_1 |^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu _1)^T \\Sigma_1 ^{-1}(x-\\mu _1)\\right)\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Parametry, które trzeba wyuczyć\n",
    "\n",
    "Nasz model jest sparametryzowany przez \n",
    "\n",
    "$\\phi $, $\\mu _0$, $\\mu _1$, $\\Sigma_0 $ i $\\Sigma_1 $. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uczenie GADa\n",
    "* Do wyznaczenie parametrów możemy zastosować metodę największej wiarygodności. \n",
    " > Co jest nam potrzebne aby zastosować tą technikę?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "------\n",
    "Definicja (Prawdopodobieństwo warunkowe)\n",
    "\n",
    "Niech $A,B\\in \\Omega$, i $P(A) \\gt 0$. \n",
    "Wtedy prawdopodobieństwem $B$ pod warunkiem $A$ nazywamy:\n",
    "$P(B|A)=\\frac{P(A\\cap B)}{P(A)}$\n",
    "\n",
    "-------\n",
    "Czyli $P(A\\cap B) = P(B|A)P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* zbiór uczący $\\left\\lbrace \\left(x^{(j)},y^{(j)}\\right) \\right\\rbrace _{j=1,\\dots ,m}$ \n",
    "* funkcję log-wiarygodności:\n",
    "\n",
    "$\\qquad$\n",
    "$\\begin{matrix}\n",
    "l(\\phi ,\\mu _0,\\mu _1,\\Sigma ) &=& \\log \\prod _{j=1}^m p \\left( x^{(j)}, y^{(j)}; \\phi ,\\mu _0,\\mu _1,\\Sigma_0,\\Sigma_1 \\right)\\\\\n",
    "&=& \\log \\prod _{j=1}^m p \\left( x^{(j)}|y^{(j)}; \\mu _0,\\mu _1,\\Sigma_0,\\Sigma_1 \\right)p(y^{(j)};\\phi )\\\\\n",
    "&=& \\sum _{j=1}^m \\log \\left[p \\left( x^{(j)}|y^{(j)}; \\mu _0,\\mu _1,\\Sigma_0,\\Sigma_1 \\right)p(y^{(j)};\\phi )\\right]\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jakie poczyniliśmy tu założenie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maksymalizując funkcję log wiarygodności względem parametrów otrzymujemy:\n",
    "\n",
    "Funkcja z 1 klamra zwraca 1 gdy to co w klamrze == 1\n",
    "\n",
    "$\\qquad$\n",
    "$\\begin{matrix}\n",
    "\\phi &=& \\frac{\\sum _{j=1}^m 1\\lbrace y^{(j)}==1\\rbrace }{m},\\\\\n",
    "\\mu _0 &=& \\frac{\\sum _{j=1}^m 1\\lbrace y^{(j)}==0\\rbrace  x^{(j)} }{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}==0\\rbrace }\\\\\n",
    "\\mu _{1} &=& \\frac{\\sum _{j=1}^{m}1\\lbrace y^{(j)}==1\\rbrace x^{(j)}}{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}==1\\rbrace }\\\\\n",
    "\\Sigma_0 &=& \\frac{1}{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}==0\\rbrace }\\sum _{j \\in C_{y=0}}^{m}(x^{(j)} - \\mu _{y^{(j)}})^{T}(x^{(j)} - \\mu _{y^{(j)}})\\\\\n",
    "\\Sigma_1 &=& \\frac{1}{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}==1\\rbrace }\\sum _{jin C_{y=1}}^{m}(x^{(j)} - \\mu _{y^{(j)}})^{T}(x^{(j)} - \\mu _{y^{(j)}})\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Klasyfikacja GAD\n",
    "Kiedy już mamy dopasowane parametry modelu możemy robić przy jego pomocy klasyfikację (przewidywania) co od nowych przypadków. Przewidywaną klasą będzie, zgodnie z tym co mówiliśmy na początku wykładu:\n",
    "\n",
    "$\\qquad y_{przewidywane} = \\arg \\max _y p(y|x) = \\arg \\max _y \\frac{p(x|y)p(y)}{p(x)}$\n",
    "\n",
    "$\\qquad \\qquad \\qquad  = \\arg \\max _y p(x|y) p(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Powierzchnie decyzyjne w GDA: QDA i LDA\n",
    "Przyjrzyjmy się teraz bliżej powierzchniom decyzyjnym powstającym w klasyfikacji GAD. Powierzchnia ta danajest równaniem:\n",
    "\n",
    "$p(x|y=0)p(y=0) = p(x|y=1)p(y=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Podstawiając jawnie postacie funkcji gęstości prawdopodobieństwa dostajemy:\n",
    "\n",
    "$\\begin{matrix}\n",
    "\\frac{1}{(2\\pi )^{n/2} |\\Sigma_0 |^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu _0)^T \\Sigma_0 ^{-1}(x-\\mu _0)\\right)\\cdot p(y=0)\\\\\n",
    " = \\frac{1}{(2\\pi )^{n/2} |\\Sigma_1 |^{1/2}} \\exp \\left( -\\frac{1}{2}(x-\\mu _1)^T \\Sigma_1 ^{-1}(x-\\mu _1)\\right)\\cdot p(y=1)\n",
    " \\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Logarytmując stronami dostajemy:\n",
    "\n",
    "$\\begin{matrix}\n",
    "-\\frac{n}{2} \\log 2\\pi - \\frac{1}{2}\\log|\\Sigma_0|  -\\frac{1}{2}(x-\\mu _0)^T \\Sigma_0 ^{-1}(x-\\mu_0) + \\log p(y=0)\\\\\n",
    " = -\\frac{n}{2} \\log 2\\pi - \\frac{1}{2}\\log|\\Sigma_1|  -\\frac{1}{2}(x-\\mu_1)^T \\Sigma_1 ^{-1}(x-\\mu_1) + \\log p(y=1)\n",
    " \\end{matrix}$\n",
    " \n",
    "redukujemy, i zauważamy elementy stałe: \n",
    " \n",
    "$\\begin{matrix}\n",
    "\\underline{- \\frac{1}{2}\\log|\\Sigma_0|} \\\\\n",
    "-\\frac{1}{2}(x-\\mu _0)^T \\Sigma_0 ^{-1}(x-\\mu_0) + \\\\\n",
    "\\underline{\\log p(y=0)}\\\\\n",
    "=  \\\\\n",
    "\\underline{- \\frac{1}{2}\\log|\\Sigma_1|} \\\\  \n",
    "-\\frac{1}{2}(x-\\mu_1)^T \\Sigma_1 ^{-1}(x-\\mu_1) + \\\\\n",
    "\\underline{\\log p(y=1)}\n",
    "\\end{matrix}$\n",
    " \n",
    " Czyli jest to jakiś **wielomian $x$ stopnia co najwyżej 2**.\n",
    " \n",
    " Stąd nazwa QDA - quadratic discriminant analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "QDA\n",
    "<img src=\"https://drive.google.com/uc?id=1HaVUlkDSeXPaZUDKo6tAKMLZkrKawCn_\" width = 800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wszystko znacznie się upraszcza jeśli założymy, że $\\Sigma_0 = \\Sigma_1 = \\Sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\begin{matrix}\n",
    " \\underline{- \\frac{1}{2}\\log|\\Sigma|} \\\\\n",
    " -\\frac{1}{2}(x-\\mu _0)^T \\Sigma ^{-1}(x-\\mu_0) + \\\\\n",
    " \\underbrace{\\log p(y=0)}\\\\\n",
    " =  \\\\\n",
    " \\underline{- \\frac{1}{2}\\log|\\Sigma|}  \\\\\n",
    " -\\frac{1}{2}(x-\\mu_1)^T \\Sigma^{-1}(x-\\mu_1) + \\\\\n",
    " \\underbrace{\\log p(y=1)} \\\\\n",
    " \\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\begin{matrix}\n",
    " -\\frac{1}{2}(x-\\mu _0)^T \\Sigma ^{-1}(x-\\mu_0)\\quad+ \\\\\n",
    " \\quad \\frac{1}{2}(x-\\mu_1)^T \\Sigma^{-1}(x-\\mu_1) \\\\\n",
    " \\\\\n",
    " =  \\\\\n",
    "{\\log p(y=1)} - {\\log p(y=0)} \\\\\n",
    " \\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\n",
    " -(x-\\mu _0)^T \\Sigma ^{-1}(x-\\mu_0) +(x-\\mu_1)^T \\Sigma^{-1}(x-\\mu_1) =\n",
    " 2 \\log \\frac{p(y=1)}{p(y=0)}\n",
    " $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$x^T\\Sigma^{-1}x - x^T\\Sigma^{-1}\\mu_1 -\\mu_1^T\\Sigma^{-1}x +\\mu_1^T\\Sigma^{-1}\\mu_1 \\\\\n",
    "-x^T\\Sigma^{-1}x + x^T\\Sigma^{-1}\\mu_0 +\\mu_0^T\\Sigma^{-1}x -\\mu_0^T\\Sigma^{-1}\\mu_0\\\\\n",
    " = \\\\\n",
    " 2 \\log \\frac{p(y=1)}{p(y=0)} \\\\\n",
    " $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ (\\mu_0-\\mu_1)^T\\Sigma^{-1}x \\\\\n",
    "+ x^T\\Sigma^{-1}(\\mu_0-\\mu_1) \\\\\n",
    " = \\\\\n",
    " 2 \\log \\frac{p(y=1)}{p(y=0)}-\\mu_1^T\\Sigma^{-1}\\mu_1 \\\\\n",
    " +\\mu_0^T\\Sigma^{-1}\\mu_0 \\\\\n",
    " $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\n",
    "2x^T\\Sigma^{-1}(\\mu_0-\\mu_1) \\\\\n",
    " = \\\\\n",
    " 2 \\log \\frac{p(y=1)}{p(y=0)}-\\mu_1^T\\Sigma^{-1}\\mu_1 \\\\\n",
    " +\\mu_0^T\\Sigma^{-1}\\mu_0 \\\\\n",
    " $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\n",
    "x^T \\\\\n",
    "\\underbrace{\\Sigma^{-1}(\\mu_0-\\mu_1)}_{wektor} \\\\\n",
    " = \\\\\n",
    "  \\underbrace{\\log \\frac{p(y=1)}{p(y=0)} + \\frac{1}{2}\\left(\\mu_0^T\\Sigma^{-1}\\mu_0 - \\mu_1^T\\Sigma^{-1}\\mu_1\n",
    " \\right)}_{const = T}\n",
    " $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1HaYte6-b2-fw7DPaNKKkCSWHSqNT0ayQ\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zauważmy, że:\n",
    "- liniowość jest wynikiem założenia równych wariancji\n",
    "- czynnik $\\Sigma^{-1}$ w wektorze na który rzutujemy koryguje jego kierunek biorąc pod uwagę 'rozciagłość' macierzy kowariancji\n",
    "- położenie progu decyzyjnego $T$ zależy od stosunku częstosći występowania klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gdybyśmy estymowali $\\Sigma$ osobno dla kazdej z klas z ciągu uczącego, to nawet jeśli w rzeczywistości kalsy mają równe macierze kowariancji to ze skończonego zbioru raczej nie dostaniemy tego.\n",
    "\n",
    "W praktyce estymujemy weariancję łączną (*pooled variance*):\n",
    "\n",
    "$\\hat \\Sigma = \\frac{1}{n-2} \\sum_{k=0}^1 \\sum_{j\\in C_k} (x^{(j)} - \\mu_k)(x^{(j)} - \\mu_k)^T$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1HbBXAYorSVWTTQdDBtqnXcaYPh6JhNHq\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jeszcze jedna uwaga praktyczna:\n",
    "    \n",
    "- We wzorze na rzutowanie występuje odwrotność macierzy kowariancji. Jest to potencjalne źródło niestabilności numerycznych jeśli wystąpią małe wartości własne\n",
    "- Aby temu zaradzić stosuje się różne regularyzacje, np.:\n",
    "  - $\\Sigma^{-1} \\rightarrow \\left(\\Sigma +\\lambda I \\right)^{-1}$ \n",
    "  albo \n",
    "  - $\\Sigma^{-1} \\rightarrow \\left((1-\\lambda)\\Sigma +\\lambda I \\right)^{-1} \\qquad \\lambda \\in (0,1)$ \n",
    "  - $\\lambda$ jest dobierana w procedurze np. walidacji krzyżowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Porównianie funkcji log-wiarygodniści dla GAD i regresji logistycznej\n",
    "\n",
    "Wielkości występujące w tym wzorze dane są przez równania.\n",
    "\n",
    "$\\qquad$ $l(\\phi ,\\mu _0,\\mu _1,\\Sigma_0,\\Sigma_1 ) = \\log \\prod _{j=1}^m p \\left( x^{(j)}, y^{(j)}; \\quad \\phi ,\\mu _0,\\mu _1,\\Sigma_0,\\Sigma_1 \\right)$ \n",
    "\n",
    "Porównajmy tą funkcję z analogiczną funkcją dla regresji logistycznej:\n",
    "\n",
    "\n",
    "$\\qquad$ $l({\\theta }) = \\log \\prod _{j=1}^{m}p(y^{(j)}|x^{(j)};\\quad \\theta )$\n",
    "\n",
    "> Zwróćmy uwagę, że w tym wzorze, jak i we wszystkich wzorach na funkcję log-wiarygodności w algorytmach dyskryminacyjnych, występuje prawdopodobieństwo warunkowe klasy $y$ mając dany $x$: $p(y|x)$, zaś w przypadku algorytmów generatywnych mamy prawdopodobieństwa wspólne $p(x,y)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussowska analiza dyskryminacyjna a regresja logistyczna\n",
    "### Przykład w 1-D:\n",
    "* dwa gaussy:\n",
    "  * pierwszy $p(x|y=0)$ odpowiada klasie y = 0 \n",
    "  * a drugi $p(x|y=1)$ klasie $y = 1$. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 100000\n",
    "np.random.seed(0)\n",
    "x_y0 = np.random.randn(N)-1  \n",
    "x_y1 = np.random.randn(N)+1\n",
    "py.subplot(1,1,1)\n",
    "py.hist(x_y0,30, density=True, facecolor='green', alpha=0.75)\n",
    "py.hist(x_y1,30, density = True, facecolor='blue', alpha=0.75)\n",
    "py.legend((\"y=0\",\"y=1\"))\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zastanówmy się jakie jest prawdopodobieństwo \n",
    "\n",
    "$\\qquad$ $p(y=1|x) = \\frac{p(x|y=1)p(y=1)}{p(x)}$ \n",
    "\n",
    "dla różnych wartości $x$ ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Połączmy nasze dwa rozkłady: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.hstack((x_y0,x_y1))\n",
    "y = np.hstack( (np.zeros(N),np.ones(N)))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Obliczamy $p(y = 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_y1 = np.sum(y==1)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Obliczamy prawdopodobieństwa $p(x|y=1)$ i $p(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = 0.3\n",
    "bins = np.arange(np.min(x),np.max(x),bin)\n",
    "p_x_y1 = np.zeros(len(bins))\n",
    "p_x = np.zeros(len(bins))\n",
    "for i,xx in enumerate(bins):\n",
    "    # prawdopodobieństwo, że x_y1 wpada do binu i-tego\n",
    "    p_x_y1[i] = np.sum( np.logical_and( xx< x_y1 , x_y1 <xx+bin ))/len(x_y1)\n",
    "     # prawdopodobieństwo, że x wpada do binu i-tego\n",
    "    p_x[i] = (np.sum( np.logical_and( xx< x , x <xx+bin )))/(len(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Stosujemy wzór Bayesa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_y1_x = (p_x_y1 * p_y1)/p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "py.subplot(1,1,1)\n",
    "py.plot( bins,p_y1_x)\n",
    "py.text(-5.5,.8,\"$p(y=1|x) = p(x|y=1)p(y=1)/p(x)$ \")\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Otrzymujemy sigmiodę!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussowska analiza dyskryminacyjna a regresja logistyczna\n",
    "Istnieje ciekawa relacja między GAD a regresją logistyczną. Obie metody dają w efekcie pewną hiperpowierzchnię separującą obszary przestrzeni wejść na przynależną do klasy 0 bądź 1.\n",
    "Prawdopodobieństwo warunkowe klasy w modelu GAD można też wyrazić w postaci:\n",
    "\n",
    "$\\qquad$ $p(y|x;\\phi ,\\Sigma ,\\mu _{0},\\mu _{1}) = \\frac{1}{1+\\exp(-\\theta ^{T}x)}$\n",
    "\n",
    "przy czym $\\theta $ jest pewną funkcją parametrów modelu $\\phi , \\Sigma , \\mu _{0},\\mu _{1}$. Co do formy uzyskujemy analogiczny wynik, chociaż w ogólności wynikające z tego proste (hiperpowierzchnie) decyzyjne będą różne dla GAD i \n",
    "regresji logistycznej, pomimo użycia tego samego zbioru uczącego. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Który model jest lepszy ?\n",
    "Możemy narysować taki schemat:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "(x|y) &\\sim & Gaussowski\\\\\n",
    "&\\Downarrow & \\textrm { ale } \\Uparrow \\textrm { nie zachodzi} \\\\\n",
    "p(y|x) &\\sim &f. logistyczna\n",
    "\\end{matrix}$\n",
    "\n",
    "* Dla wielu rozkładów $(x|y)$ należących do rodziny wykładniczej otrzymujemy $p(y|x)$ w postaci logistycznej. \n",
    "* Wynika stąd, że założenie gaussowskiej postaci $(x|y)$ jest mocniejszym założeniem niż logistyczna postać $p(y|x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Zatem odpowiedź, które podejście jest lepsze zależy od danych. \n",
    "* Model GAD oparty jest o założenie, że rozkłady warunkowe danych $p(x|y)$ są wielowymiarowymi rozkładami normalnymi.\n",
    "* Jeśli to założenie jest prawdziwe, to model GAD wykorzystuje więcej informacji, bo ”zna” cały rozkład danych - dane ze zbioru uczącego służą jedynie do estymacji parametrów tego rozkładu. \n",
    "* Z drugiej strony regresja logistyczna robi znacznie słabsze założenia co do danych w związku z czym jest bardziej odporna na odstępstwa rozkładów danych wejściowych od założeń."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naiwny Klasyfikator Bayesa\n",
    "\n",
    "* Klasyfikator GAD działał na danych ciągłych. \n",
    "* Jak można zbudować kalsyfikator generatywny dla danych dyskretnych?\n",
    "* Jako przykład omówimy naiwny klasyfikator Bayesa. Klasyfikator ten zaprezentujemy na przykładzie filtra antyspamowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Reprezentacja listu\n",
    "* Załóżmy, że jako zbiór uczący mamy kolekcję listów oznaczonych jako spam albo nie-spam\n",
    "> Jak można reprezentować listy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jednym z popularnych podejść jest metoda słownikowa. Przeglądamy duży zestaw listów, sporządzamy listę słów, które wystąpiły w tych listach, porządkujemy alfabetycznie i otrzymujemy _słownik_.\n",
    "\n",
    "* Mając taki słownik możemy każdy list zakodować jako wektor kolumnowy złożony z zer i jedynek. Jedynka na i-tej pozycji oznacza, że w liście wystąpiło i-te słowo z naszego słownika. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Przykładowy list mógłby wyglądać tak:\n",
    "\n",
    "$\\qquad$ \n",
    "$\n",
    "x = \\left[\n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\vdots \\end{array}\n",
    "\\right]\n",
    "\\begin{array}{l}\n",
    "aby \\\\\n",
    "ale \\\\\n",
    "\\vdots \\\\\n",
    "pozdrawiam \\\\\n",
    "\\vdots \\\\\n",
    "witaj \\\\\n",
    "\\vdots \\\\\n",
    "widzialem \\\\\n",
    "\\vdots \\end{array}\n",
    "$\n",
    "\n",
    "* Każdy $x_{i}$ ($i$-ta współrzędna wektora $x$) może przyjąć wartość 1 albo 0 w zależności od tego czy $i$-te słowo ze słownika wystąpiło w liście czy też nie. \n",
    "* Zauważmy, że kodowanie to pomija informację o częstości danego słowa w liście."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Rozważania o rozmiarach\n",
    "* Widać, że rozmiar $x$ może być bardzo duży. Jest on równy rozmiarowi słownika.\n",
    "* Mając wybrany sposób reprezentacji listów możemy przystąpić do budowania modelu dyskryminacyjnego. \n",
    "* Potrzebjemy wyznaczyć $p(x|y)$. \n",
    "* Jeśli rozmiar naszego słownika to 5000 słów to $x$ są 5000-wymiarowymi wektorami z wartościami 0 i 1. \n",
    "* Gdzybyśmy chcieli zamodelować to rozkładem wielorakim to mielibyśmy $2^{5000}-1$ możliwych stanów do zareprezentowania i tyle potrzebowalibyśmy oszacować parametrów. \n",
    "> To zdecydowanie za dużo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Naiwne założenie Bayesa\n",
    "* Aby sobie jakoś z tym problemem poradzić posłużymy się tzw. naiwnym założeniem Bayesa. \n",
    "> Założymy mianowicie, że słowa są **warunkowo niezależne**. \n",
    "* W praktyce oznacza to tyle, że jeśli wiem, że dany list jest spamem, to dodatkowa wiedza, że występuje w nim słowo 'wygrałeś' ($x_{3000}$) nie wpływa na moje oszacowanie prawdopodobieństwa, że w tym liście występuje słowo 'kliknij' ($x_{1234}$).\n",
    "* Formalnie oznacza to, że $p(x_{1234}|y) = p(x_{1234}|y,x_{3000})$. Uwaga: Nie jest to to samo co założenie, że słowa te są od siebie niezależne. \n",
    "* Niezależność słów zapisalibyśmy jako $p(x_{1234}) = p(x_{1234}|x_{3000})$.\n",
    "\n",
    "* Dzięki założeniu warunkowej niezależności możemy zapisać:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "p(x_{1},\\dots ,x_{5000}|y) &=& p(x_{1}|y)p(x_{2}|y,x_{1})p(x_{3}|y,x_{1},x_{2}),\\dots ,p(x_{5000}|y,x_{1},\\dots ,x_{4999})\\\\\n",
    "&=& p(x_{1}|y)p(x_{2}|y)p(x_{3}|y),\\dots ,p(x_{5000}|y) \\\\\n",
    "&=& \\prod _{i=1}^{n}p(x_{i}|y)\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Ostatecznie nasz model jest sparametryzowany przez:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "\\phi _{i|y=0} &=& p(x_{i}=1|y=0) \\\\\n",
    "\\phi _{i|y=1} &=& p(x_{i}=1|y=1) \\\\\n",
    "\\phi _{y} &=& p(y=1)\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funkcja wiarygodności\n",
    "Mając dany zbiór uczący $\\left\\lbrace  \\left( x^{(j)},y^{(j)} \\right)\\right\\rbrace _{j=1,\\dots ,m}$\n",
    "możemy wypisać funkcję wiarygodności:\n",
    "\n",
    "$\\qquad$ $L(\\phi _{y}, \\phi _{i|y=0},\\phi _{i|y=1}) = \\prod _{j=1}^{m} p(x^{(j)},y^{(j)}) = \\prod _{j=1}^{m} p(x^{(j)}|y^{(j)})p(y^{(j)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Parametry wynikające z zasady największej wiarygodności\n",
    "Maksymalizując tą fuknkcję za względu na parametry $\\phi _{y}, \\phi _{i|y=0},\\phi _{i|y=1}$ otrzymujemy:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "\\phi _{i|y=0} &=& \\frac{ \\sum _{j=1}^m 1\\lbrace x_i^{(j)} == 1 \\wedge y^{(j)}== 0 \\rbrace  }{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}== 0\\rbrace  } \\\\\n",
    "\\phi _{i|y=1} &=& \\frac{ \\sum _{j=1}^m 1\\lbrace x_i^{(j)} == 1 \\wedge y^{(j)}== 1 \\rbrace  }{\\sum _{j=1}^{m} 1\\lbrace y^{(j)}== 1\\rbrace  } \\\\\n",
    "\\phi _{y} &=& \\frac{ \\sum _{j=1}^m 1\\lbrace  y^{(j)}== 1 \\rbrace  }{m }\n",
    "\\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Klasyfikacja nowego listu\n",
    "Teraz aby sklasyfikować nowy list z cechami $x$ obliczamy:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "p(y=1|x) &=& \\frac{p(x|y=1)p(y=1)}{p(x)}\\\\\n",
    "&=& \\frac{\\prod _{i=1}^{n} p(x_{i}|y=1)p(y=1)}{( \\prod _{i=1}^{n}p(x_{i}|y=0))p(y=0)+(\\prod _{i=1}^{n}p(x|y=1))p(y=1)}\n",
    "\\end{matrix}$\n",
    "\n",
    "* aby obliczyć prawdopodobieństwo przynależności do klasy 0 możemy skorzystać z: $p(y=0|x) = 1-p(y=1|x)$)\n",
    "* i wybieram klasę do której przynależność jest bardziej prawdopodobna (klasyfikator Bayesa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A gdy chcemy klasyfikować więcej opcji?\n",
    "* W tym przykładzie rozważaliśmy sytuację gdy prawdopodobieństwa warunkowe poszczególnych $x_{i}$ były modelowane rozkładem Bernoulliego. \n",
    "\n",
    "* Widać, że gdyby $x_{i}$ mogło przyjmować $k$ dyskretnych wartości to należałoby modelować je za pomocą rozkładu wielorakiego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem\n",
    "Wyobraźmy sobie, że słownik zawiera słowo 'niezapominajka' ale, że zbiór uczący nie zawierał listu w którym słowo to by wystąpiło, załóżmy że ma ono indeks 2576 w naszym słowniku. Wówczas oszacowane parametry $\\phi $ dla tego słowa to:\n",
    "\n",
    "$\\qquad$ $\\begin{matrix}\n",
    "\\phi _{2576|y=0} &=& \\frac{ \\sum _{j=1}^m 1\\lbrace x_{2576}^{(j)} == 1 \\wedge y^{(j)} == 0 \\rbrace  }{\\sum _{j=1}^{m} 1\\lbrace y^{(j)} == 0\\rbrace  } = 0 \\\\\n",
    "\\phi _{2576|y=1} &=& \\frac{ \\sum _{j=1}^m 1\\lbrace x_{2576}^{(j)} == 1 \\wedge y^{(j)} == 1 \\rbrace  }{\\sum _{j=1}^{m} 1\\lbrace y^{(j)} == 1\\rbrace  } = 0\n",
    "\\end{matrix}$\n",
    "\n",
    "bo nigdy się nie zdarzyło aby słowo to wystąpiło w klasie spam i w klasie nie-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jeżeli teraz policzymy dla tego słowa prawdopodobieństwo klasy 1 to :\n",
    "\n",
    "$\\qquad$ $p(y=1|x) = \\frac{\\prod _{i=1}^{n} p(x_{i}|y=1)p(y=1)}{( \\prod _{i=1}^{n}p(x_{i}|y=0))p(y=0)+(\\prod _{i=1}^{n}p(x_{i}|y=1))p(y=1)} =\\frac{0}{0}$\n",
    "\n",
    "ponieważ w każdym z iloczynów $\\prod _{i=1}^{n} p(x_{i}|y=1)$ występuje czynnik $p(x_{2576}|y)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Czyli nie da się określić prawdopodobieństwa przynależności listu $x$ do klasy spam albo nie-spam ze względu na jedno słowo, które nie występowało w zbiorze uczącym! \n",
    "\n",
    "* W tym przykładzie można by oczywiście zaproponować inny sposób konstrukcji słownika aby do takiej sytuacji nie doszło, albo preprocesing listów polegający na usunięciu słów. które nie należą do słownika."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wygładzanie Laplace'a\n",
    "* Problem ten bierze się ze sposobu szacowania parametrów $\\phi _{i}$.\n",
    "* Rozważmy zagadnienie oszacowania średniej w rozkładzie wielorakim, w którym zmienna $z$ przyjmuje jedną z $\\lbrace 1,\\dots ,k\\rbrace $ wartości i rozkład ten jest sparametryzowany przez $\\phi _{i} = p(z=i)$. \n",
    "* Do dyspozycji mamy $m$ niezależnych obserwacji $\\lbrace z^{(1)},\\dots ,z^{(m)}\\rbrace $. \n",
    "* Z metody największej wiarygodności otrzymujemy estymaty (stosunek liczby $z =i$ do liczby wszystkich obserwacji):\n",
    "\n",
    "$\\qquad$ $\\phi _{i} = \\frac{\\sum _{j=1}^{m} 1\\lbrace z^{(j)} == i\\rbrace }{m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jednak fakt, że w skończonym zbiorze obserwacji nie wystąpiła ani razu któraś z możliwych wartości $z$ nie powinien skutkować tym, że przypisujemy zerowe prawdopodobieństwo tej możliwości. \n",
    "* Metodą powszechnie stosowaną na poprawę tej estymaty jest tzw. wygładzanie Laplacea. \n",
    "* Modyfikuje ono estymatę otrzymaną metodą największej wiarygodności w następujący sposób:\n",
    "\n",
    "$\\qquad$ $\\phi _{i} = \\frac{\\sum _{j=1}^{m} 1\\lbrace z^{(j)} == 1\\rbrace  +1 }{m+k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Łatwo zauważyć, że ten estymator też spełnia warunki narzucone przez interpretację probabilistyczną:\n",
    "\n",
    "$\\qquad \\sum _{i=1}^{k} \\phi _{i} =1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.12 ('spyder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "livereveal": {
   "progress": true,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif",
   "transition": "fade"
  },
  "vscode": {
   "interpreter": {
    "hash": "c288bdb25ca9e4767fa3e338ce28882ca341a961656781e13252079ed73b75e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
